{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Training an RBM on MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we train a simple RBM on the MNIST dataset and visualize its learned filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  The Imports\n",
    "First, we import Tensorflow and numpy packages, as well as the packages we need to visualize the learned filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the `xrbm.models` module, which contains the RBM model class, as well as the `xrbm.train` module, which contains the `CD-k` approximation algorithm that we use for training our RBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xrbm.models\n",
    "import xrbm.train\n",
    "import xrbm.losses\n",
    "from xrbm.utils.vizutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Training Data\n",
    "\n",
    "We use the MNIST dataset that is provided by the Tensorflow package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "data_sets = input_data.read_data_sets('MNIST_data', False)\n",
    "training_data = data_sets.train.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up the Parameters\n",
    "\n",
    "The number of the visible units of the RBM equals to the number of the dimensions of the training data. As each image in MNIST is `28x28`, the number of total pixels is `784`. \n",
    "\n",
    "We use `200` hidden units, choose a learning rate of `0.1`, and set to train the model for `15` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_vis         = training_data[0].shape[0] #=784\n",
    "num_hid         = 200\n",
    "learning_rate   = 0.1\n",
    "batch_size      = 100\n",
    "training_epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an RBM model with the parameters\n",
    "\n",
    "We create an RBM model, and set the number of visible and hidden units. We can also give it a name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's reset the tensorflow graph in case we want to rerun the code\n",
    "tf.reset_default_graph()\n",
    "\n",
    "rbm = xrbm.models.RBM(num_vis=num_vis, num_hid=num_hid, name='rbm_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the mini-batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_idxs = np.random.permutation(range(len(training_data)))\n",
    "n_batches  = len(batch_idxs) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a placeholder for the mini-batch data during training.\n",
    "\n",
    "We use the CD-k algorithm for training the RBM. For this, we create an instance of the `CDApproximator` from the `xrbm.train` module and pass the learning rate to it. \n",
    "\n",
    "We then define our training op using the `CDApproximator`'s `train` method, passing the RBM model and the placeholder for the data. \n",
    "\n",
    "In order to monitor the training process, we calculate the reconstruction cost of the model at each epoch, using the `rec_cost_op`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_data     = tf.placeholder(tf.float32, shape=(None, num_vis))\n",
    "\n",
    "cdapproximator = xrbm.train.CDApproximator(learning_rate=learning_rate)\n",
    "train_op       = cdapproximator.train(rbm, vis_data=batch_data)\n",
    "\n",
    "reconstructed_data,_,_,_ = rbm.gibbs_sample_vhv(batch_data)\n",
    "xentropy_rec_cost  = xrbm.losses.cross_entropy(batch_data, reconstructed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to run everything and see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create figure first so that we use the same one to draw the filters on during the training\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        for batch_i in range(n_batches):\n",
    "            # Get just minibatch amount of data\n",
    "            idxs_i = batch_idxs[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "            \n",
    "            # Run the training step\n",
    "            sess.run(train_op, feed_dict={batch_data: training_data[idxs_i]})\n",
    "    \n",
    "        reconstruction_cost = sess.run(xentropy_rec_cost, feed_dict={batch_data: training_data})\n",
    "\n",
    "        W = rbm.W.eval().transpose()\n",
    "        filters_grid = create_2d_filters_grid(W, filter_shape=(28,28), grid_size=(10, 20), grid_gap=(1,1))\n",
    "        \n",
    "        title = ('Epoch %i / %i | Reconstruction Cost = %f'%\n",
    "                (epoch+1, training_epochs, reconstruction_cost))\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.imshow(filters_grid, cmap='gray')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(fig)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tfconda35]",
   "language": "python",
   "name": "conda-env-tfconda35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
